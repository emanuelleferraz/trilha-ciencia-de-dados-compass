# üìä Entrega - Sprint 06

Nessa Sprint 06, a trilha foi dividida entre 3 cursos, sendo eles: **Forma√ß√£o Processamento de Linguagem Natural, LLMs e GenAI**, **MLOps: Implata√ß√£o e Opera√ß√£o de Modelos de Machine Learning** e **Face Recognition with Machine Learning**.

## Link do V√≠deo
---

# üìù Exerc√≠cios

### Forma√ß√£o Processamento de Linguagem Natural, LLMs e GenAI
Durante o curso, n√£o foram realizados diretamente exerc√≠cios, dessa forma, achei interessante fazer o upload dos arquivos notebooks referentes as aulas. Segue abaixo os arquivos divididos pela se√ß√£o do curso:
1. **NLP com Spacy**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20nlp/spacy/spacy.ipynb).

2. **NLP com NLTK**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20nlp/nltk/nltk.ipynb).    

3. **Machine Learning e Deep Learning com NLP na pr√°tica**:

    ‚û°Ô∏è Confira o notebook de [machine learning](./exercicios/curso%20de%20nlp/machine%20e%20deep%20learning%20nlp/ml-spam.ipynb).

    ‚û°Ô∏è Confira o primeiro notebook de [rede neural](./exercicios/curso%20de%20nlp/machine%20e%20deep%20learning%20nlp/rede-neural.ipynb).

    ‚û°Ô∏è Confira o segundo notebook de [rede neural](./exercicios/curso%20de%20nlp/machine%20e%20deep%20learning%20nlp/rede-neural-2.ipynb).


4. **Analise de Sentimentos**:

    ‚û°Ô∏è Confira o notebook de [LSTM](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/lstm.ipynb).

    ‚û°Ô∏è Confira o notebook de [bert](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/bert.ipynb).

    ‚û°Ô∏è Confira o notebook de [regras supervisionado](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/regras-supervisionado.ipynb).

    ‚û°Ô∏è Confira o notebook de [vader](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/vader.ipynb).

5. **Transformers, Bert e GPT**:

    ‚û°Ô∏è Confira o notebook de [gera√ß√£o de textos](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/geracao-texto.ipynb).

    ‚û°Ô∏è Confira o notebook de [preenchimento de lacunas](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/preenchimento-lacunas.ipynb).

    ‚û°Ô∏è Confira o notebook de [perguntas e respostas](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/perguntas-respostas.ipynb).

    ‚û°Ô∏è Confira o notebook de [resumo de textos](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/resumo-textos.ipynb).

6. **Modelagem de T√≥picos**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20nlp/modelagem%20de%20topicos/bert.ipynb).


### MLOps: Implata√ß√£o e Opera√ß√£o de Modelos de Machine Learning
Como no curso de NLP, o de MLOps tamb√©m n√£o tiveram exerc√≠cios. Dado isso, estarei seguindo o mesmo padr√£o e inserindo os notebooks do curso como exerc√≠cios.

1. **MLFlow com Naive Bayes**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20mlops/MLFlow-NB.ipynb).

2. **MLFlow com Random Forest**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20mlops/MLFlow-RF.ipynb).

3. **MLFlow com Keras**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20mlops/MLFlow-Keras.ipynb).


# üìÇ Evid√™ncias

### Forma√ß√£o Processamento de Linguagem Natural, LLMs e GenAI
Nesse curso, foram aprofundados conceitos de processamento de linguagem natural, com bibliotecas como Spacy, NLTK e Spark, bem como LLMs com Bert e GPT, al√©m de analise de sentimentos. Segue abaixo evid√™ncias das se√ß√µes:

- **NLP com Spacy**: O **spacy** √© uma biblioteca de **Processamento de Linguagem Natural (NLP)** com a vantagem de ter bom desempenho e escalabilidade. A biblioteca fornece diversas funcionalidades comuns de NLP como tokeniza√ß√£o, lematiza√ß√£o, an√°lise sint√°tica, reconhecimento de entidades nomeadas (NER) e compara√ß√£o de similaridade entre palavras e senten√ßas.

- Come√ßando pela funcionalidade de Tokeniza√ß√£o, que √© o processo de dividir um texto em unidades menores chamadas **tokens**, como palavras ou pontua√ß√µes. O **spacy** permite uma tokeniza√ß√£o eficiente e tamb√©m possui uma lista integrada de **stop words**, que s√£o palavras consideradas sem grande relev√¢ncia.  Posteriormente, foi feito o processo de **POS-Tagging (Part-of-Speech Tagging)**, que identifica a classe gramatical de cada palavra no texto, como substantivo, verbo ou adjetivo. Um pouco dos resultados ser√° mostrado nas imagens abaixo:

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-tok.png" alt="Tokeniza√ß√£o" width="400">
    <img src="./evidencias/curso de nlp/spacy-postag.png" alt="PosTagging" width="400">
</p>

- Um ponto interessante √© que o spacy mant√©m um **vocabul√°rio** interno onde cada palavra recebe um **ID √∫nico**. Esse vocabul√°rio permite mapear as palavras para seus ids correspondentes. A forma de indentifiv√°-los est√° na imagem abaixo. Al√©m disso, uma das funcionalidades mais legais do spacy √© a **similaridade entre palavras e senten√ßas**, utilizando embeddings sem√¢nticos para entender rela√ß√µes entre termos.

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-vocab.png" alt="Vocabul√°rio" width="400">
    <img src="./evidencias/curso de nlp/spacy-similarity.png" alt="Similaridade" width="400">
</p>

- Outro ponto interessante √© o **Reconhecimento de Entidades Nomeadas (NER)** que permite identificar elementos importantes em um texto, como **nomes de pessoas, locais, organiza√ß√µes, datas e valores monet√°rios**. O **spaCy** classifica automaticamente essas entidades usando `ent.label_`.  

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-entidades.png" alt="Entidades" width="400">
</p>

- Por √∫ltimo,  foi poss√≠vel verificar graficamente a an√°lise das depend√™ncias com **displacy**. O displacy √© uma ferramenta visual do spacy que permite representar graficamente a estrutura de um texto. Ele exibe a rela√ß√£o entre os tokens, mostrando suas tags gramaticais e conex√µes sint√°ticas de maneira intuitiva.  Abaixo √© poss√≠vel ver uma parte dessa an√°lise.

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-display.png" alt="Depend√™ncias" width="500">
</p>

- O **NLTK (Natural Language Toolkit)** √© uma das bibliotecas mais utilizadas para **Processamento de Linguagem Natural (NLP)** em Python. Ele fornece muitas ferramentas para an√°lise de texto, incluindo tokeniza√ß√£o, stemming, lematiza√ß√£o, an√°lise sint√°tica e reconhecimento de entidades nomeadas, como vistas no curso de Spacy.

- Como as t√©cnicas de **NLP** s√£o praticamente as mesmas aplicadas com spacy, optei por n√£o inserir evid√™ncias de processos como tokeniza√ß√£o, POS-Tagging e outros j√° mencionados anteriormente. Por√©m, um ponto interessante que n√£o foi abordado no spacy √© a busca pela **frequ√™ncia de uma palavra em uma senten√ßa**, conforme mostrado na imagem abaixo:  

<p align="center">
    <img src="./evidencias/curso de nlp/nltk-frequency.png" alt="Frequ√™ncias" width="500">
</p>

- **Machine Learning e Deep Learning com NLP na Pr√°tica**:

- **Machine Learning com NLP**: Nesta parte, foi utilizado um **dataset de spam** para prever se um e-mail √© **spam ou n√£o**. Para isso, foram utilizados os passos comuns ao fazer previs√µes:

- **Prepara√ß√£o dos dados**: Separa√ß√£o das vari√°veis em features e target.  
- **Vetoriza√ß√£o**: Aplica√ß√£o do `TfidfVectorizer` para converter os textos em representa√ß√µes num√©ricas.  
- **Treinamento do modelo**: Utiliza√ß√£o do algoritmo **Random Forest** para aprendizado.  
- **Avalia√ß√£o**: Foram realizadas previs√µes e as m√©tricas obtidas demonstraram um bom desempenho do modelo. 

Por√©m, ao inserir **novos dados**, o modelo apresentou erro na previs√£o, conforme ilustrado na imagem abaixo. Mas isso n√£o significa que o modelo tem desempenho ruim.

<p align="center">
    <img src="./evidencias/curso de nlp/ml-spam.png" alt="Frequ√™ncias" width="500">
</p>

- **Deep Learning com NLP**: O mesmo problema foi abordado utilizando **Redes Neurais**, seguindo um fluxo semelhante, mas usando uma abordagem diferente de vetoriza√ß√£o com o `CountVectorizer` e **redes neurais** para treinamento.

- **An√°lise de Sentimentos**:
Para a an√°lise de sentimentos, foram testadas diferentes abordagens, incluindo:  
- **LSTM (Long Short-Term Memory)**  
- **BERT (Bidirectional Encoder Representations from Transformers)**  
- **Regras Supervisionadas**  

Contudo, o exemplo apresentado abaixo utiliza o **Vader**, uma ferramenta baseada em regras, otimizada para an√°lise de sentimentos em textos curtos, como coment√°rios e tamb√©m tweets. No exemplo, foram utilizada senten√ßas simples e atrav√©s do `mas.popularity_score()` foi poss√≠vel obter as m√©tricas correspondentes as tr√™s classes negativo, positivo, neutro.

<p align="center">
    <img src="./evidencias/curso de nlp/vader-analise-sentimentos.png" alt="Vader" width="500">
</p>

- Outra parte bem legal dos cursos foi a utiliza√ß√£o do **Transformers** com o **Hugging Face Hub**. Atrav√©s deles, foi poss√≠vel testar modelos j√° treinados para diferentes tarefas de NLP.  

Primeiramente, exploramos a funcionalidade de **Perguntas e Respostas**, onde um modelo recebe um texto e responde perguntas com base nele. Outra aplica√ß√£o interessante foi o **preenchimento de lacunas**, onde o modelo completa palavras faltantes dentro de uma frase, demonstrando sua capacidade contextual.

<p align="center">
    <img src="./evidencias/curso de nlp/pergunta-resposta.png" alt="*" width="400">
    <img src="./evidencias/curso de nlp/lacunas.png" alt="#" width="400">
</p>

### MLOps: Implata√ß√£o e Opera√ß√£o de Modelos de Machine Learning
O curso de MLOps foi de longe um dos mais interessantes e proveitsos da trilha. Nesse curso foi poss√≠vel entender o processo por tr√°s do registro e implanta√ß√£o de um modelo de machine learning utilizando **MLFlow**.

Com o MLflow, foi poss√≠vel:  
- **Registrar modelos treinados** e acompanhar suas vers√µes. Posteriormente foi poss√≠vel**interagir com a interface do MLflow**, visualizando m√©tricas e artefatos dos experimentos.  

- O primeiro modelo a ser registrado foi o de **Naive Bayes**:
<p align="center">
    <img src="./evidencias/curso mlops/mlflow-ui.png" alt="MLFLOW" width="600">
</p>

Outro ponto interessante √© que foi poss√≠vel gerar gr√°ficos para ter uma no√ß√£o do desempenho, como o gr√°fico de **Matriz de Confus√£o** e o gr√°fico de **ROC**:

<p align="center">
    <img src="./evidencias/curso mlops/matriz1.png" alt="Matriz de Confus√£o" width="400">
    <img src="./evidencias/curso mlops/roc1.png" alt="ROC" width="400">
</p>

- O segundo modelo a ser registrado foi o de **Random Forest**:
<p align="center">
    <img src="./evidencias/curso mlops/mlflow-ui2.png" alt="MLFLOW" width="600">
</p>

O modelo possui mais registros pois a execu√ß√£o foi atrav√©s de um looping aumentando o n√∫mero de √°rvores a cada vez que rodasse, sendo primeiro com 50, depois 100, 500, 750 e 1000. Abaixo, segue a compara√ß√£o da matriz de confus√£o com todas as cinco quantidades de √°rvores mencionadas anteriormente.

<p align="center">
    <img src="./evidencias/curso mlops/matriz_rf1.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf2.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf3.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf4.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf5.png" alt="Matriz de Confus√£o" width="300">
</p>

- O terceiro modelo a ser registrado foi utilizando o **Keras**:
<p align="center">
    <img src="./evidencias/curso mlops/mlflow-ui3.png" alt="MLFLOW" width="600">
</p>