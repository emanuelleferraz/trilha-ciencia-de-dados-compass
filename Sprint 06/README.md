# üìä Entrega - Sprint 06

Nessa Sprint 06, a trilha foi dividida entre 3 cursos, sendo eles: **Forma√ß√£o Processamento de Linguagem Natural, LLMs e GenAI**, **MLOps: Implata√ß√£o e Opera√ß√£o de Modelos de Machine Learning** e **Face Recognition with Machine Learning**.

## Link do V√≠deo
https://compasso-my.sharepoint.com/:v:/r/personal/emanuelle_lima_pb_compasso_com_br/Documents/emanuelle.lima-sprint06.mp4?csf=1&web=1&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=f59e7y
---

# üìù Exerc√≠cios

### Forma√ß√£o Processamento de Linguagem Natural, LLMs e GenAI
Durante o curso, n√£o foram realizados diretamente exerc√≠cios, dessa forma, achei interessante fazer o upload dos arquivos notebooks referentes as aulas. Segue abaixo os arquivos divididos pela se√ß√£o do curso:
1. **NLP com Spacy**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20nlp/spacy/spacy.ipynb).

2. **NLP com NLTK**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20nlp/nltk/nltk.ipynb).    

3. **Machine Learning e Deep Learning com NLP na pr√°tica**:

    ‚û°Ô∏è Confira o notebook de [machine learning](./exercicios/curso%20de%20nlp/machine%20e%20deep%20learning%20nlp/ml-spam.ipynb).

    ‚û°Ô∏è Confira o primeiro notebook de [rede neural](./exercicios/curso%20de%20nlp/machine%20e%20deep%20learning%20nlp/rede-neural.ipynb).

    ‚û°Ô∏è Confira o segundo notebook de [rede neural](./exercicios/curso%20de%20nlp/machine%20e%20deep%20learning%20nlp/rede-neural-2.ipynb).


4. **Analise de Sentimentos**:

    ‚û°Ô∏è Confira o notebook de [LSTM](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/lstm.ipynb).

    ‚û°Ô∏è Confira o notebook de [bert](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/bert.ipynb).

    ‚û°Ô∏è Confira o notebook de [regras supervisionado](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/regras-supervisionado.ipynb).

    ‚û°Ô∏è Confira o notebook de [vader](./exercicios/curso%20de%20nlp/analise%20de%20sentimentos/vader.ipynb).

5. **Transformers, Bert e GPT**:

    ‚û°Ô∏è Confira o notebook de [gera√ß√£o de textos](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/geracao-texto.ipynb).

    ‚û°Ô∏è Confira o notebook de [preenchimento de lacunas](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/preenchimento-lacunas.ipynb).

    ‚û°Ô∏è Confira o notebook de [perguntas e respostas](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/perguntas-respostas.ipynb).

    ‚û°Ô∏è Confira o notebook de [resumo de textos](./exercicios/curso%20de%20nlp/transformers,%20bert%20e%20gpt/resumo-textos.ipynb).

6. **Modelagem de T√≥picos**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20nlp/modelagem%20de%20topicos/bert.ipynb).


### MLOps: Implata√ß√£o e Opera√ß√£o de Modelos de Machine Learning
Como no curso de NLP, o de MLOps tamb√©m n√£o tiveram exerc√≠cios. Dado isso, estarei seguindo o mesmo padr√£o e inserindo os notebooks do curso como exerc√≠cios.

1. **MLFlow com Naive Bayes**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20mlops/MLFlow-NB.ipynb).

2. **MLFlow com Random Forest**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20mlops/MLFlow-RF.ipynb).

3. **MLFlow com Keras**:

    ‚û°Ô∏è Confira o [notebook](./exercicios/curso%20de%20mlops/MLFlow-Keras.ipynb).


### Face Recognition with Machine Learning
Seguindo o mesmo esquema dos cursos anteriores, como n√£o foram feitos exerc√≠cios, estarei inserindo os notebooks referentes as aulas pr√°ticas do curso.

1. **OpenCV**:

    ‚û°Ô∏è Confira o notebook de [valores e pixels](./exercicios/curso%20de%20reconhecimento%20facial/openCV/01-values-pixels.ipynb).

    ‚û°Ô∏è Confira o notebook de [lendo a imagem](./exercicios/curso%20de%20reconhecimento%20facial/openCV/02-reading-image.ipynb).

    ‚û°Ô∏è Confira o notebook de [redimensionando a imagem](./exercicios/curso%20de%20reconhecimento%20facial/openCV/03-image-resizing.ipynb).

    ‚û°Ô∏è Confira o notebook de [detec√ß√£o de face](./exercicios/curso%20de%20reconhecimento%20facial/openCV/04-face-detection.ipynb).

2. **Face Recognition with Machine Learning**:

    ‚û°Ô∏è Confira o notebook de [cortando as faces (pr√©-processamento)](./exercicios/curso%20de%20reconhecimento%20facial/face%20recognition%20machine%20learning/01-pre-processamento-crop.ipynb).

    ‚û°Ô∏è Confira o notebook de [EDA](./exercicios/curso%20de%20reconhecimento%20facial/face%20recognition%20machine%20learning/02-pre-processamento-eda.ipynb).

    ‚û°Ô∏è Confira o notebook de [eigen image](./exercicios/curso%20de%20reconhecimento%20facial/face%20recognition%20machine%20learning/03-feature-extraction-eigen.ipynb).

    ‚û°Ô∏è Confira o notebook de [treinando com machine learning](./exercicios/curso%20de%20reconhecimento%20facial/face%20recognition%20machine%20learning/04-machine-learning.ipynb).

    ‚û°Ô∏è Confira o notebook de [pipeline de face recognition](./exercicios/curso%20de%20reconhecimento%20facial/face%20recognition%20machine%20learning/05-pipeline.ipynb).

    ‚û°Ô∏è Confira o notebook de [previs√£o](./exercicios/curso%20de%20reconhecimento%20facial/face%20recognition%20machine%20learning/06-predict.ipynb).

Um ponto importante a se destacar nesse t√≥pico de exerc√≠cios √© que, do curso de Face Recognition n√£o estar√£o os notebooks da se√ß√£o referente ao desenvolvimento de um aplicativo web para detec√ß√£o de faces. Outro ponto, √© que no curso de NLP, n√£o consegui realizar as aulas no Databricks, uma vez que n√£o me possibilitaram a cria√ß√£o de um Cluster (curso √© antigo, mudaram algumas coisas). Da mesma forma, tive problemas com a se√ß√£o final do curso de MLOps e n√£o consegui usar o modelo implantado no pequeno c√≥digo python feito ao final.


# üìÇ Evid√™ncias

### Forma√ß√£o Processamento de Linguagem Natural, LLMs e GenAI
Nesse curso, foram aprofundados conceitos de processamento de linguagem natural, com bibliotecas como Spacy, NLTK e Spark, bem como LLMs com Bert e GPT, al√©m de analise de sentimentos. Segue abaixo evid√™ncias das se√ß√µes:

- **NLP com Spacy**: O **spacy** √© uma biblioteca de **Processamento de Linguagem Natural (NLP)** com a vantagem de ter bom desempenho e escalabilidade. A biblioteca fornece diversas funcionalidades comuns de NLP como tokeniza√ß√£o, lematiza√ß√£o, an√°lise sint√°tica, reconhecimento de entidades nomeadas (NER) e compara√ß√£o de similaridade entre palavras e senten√ßas.

- Come√ßando pela funcionalidade de Tokeniza√ß√£o, que √© o processo de dividir um texto em unidades menores chamadas **tokens**, como palavras ou pontua√ß√µes. O **spacy** permite uma tokeniza√ß√£o eficiente e tamb√©m possui uma lista integrada de **stop words**, que s√£o palavras consideradas sem grande relev√¢ncia.  Posteriormente, foi feito o processo de **POS-Tagging (Part-of-Speech Tagging)**, que identifica a classe gramatical de cada palavra no texto, como substantivo, verbo ou adjetivo. Um pouco dos resultados ser√° mostrado nas imagens abaixo:

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-tok.png" alt="Tokeniza√ß√£o" width="400">
    <img src="./evidencias/curso de nlp/spacy-postag.png" alt="PosTagging" width="400">
</p>

- Um ponto interessante √© que o spacy mant√©m um **vocabul√°rio** interno onde cada palavra recebe um **ID √∫nico**. Esse vocabul√°rio permite mapear as palavras para seus ids correspondentes. A forma de indentifiv√°-los est√° na imagem abaixo. Al√©m disso, uma das funcionalidades mais legais do spacy √© a **similaridade entre palavras e senten√ßas**, utilizando embeddings sem√¢nticos para entender rela√ß√µes entre termos.

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-vocab.png" alt="Vocabul√°rio" width="400">
    <img src="./evidencias/curso de nlp/spacy-similarity.png" alt="Similaridade" width="400">
</p>

- Outro ponto interessante √© o **Reconhecimento de Entidades Nomeadas (NER)** que permite identificar elementos importantes em um texto, como **nomes de pessoas, locais, organiza√ß√µes, datas e valores monet√°rios**. O **spaCy** classifica automaticamente essas entidades usando `ent.label_`.  

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-entidades.png" alt="Entidades" width="400">
</p>

- Por √∫ltimo,  foi poss√≠vel verificar graficamente a an√°lise das depend√™ncias com **displacy**. O displacy √© uma ferramenta visual do spacy que permite representar graficamente a estrutura de um texto. Ele exibe a rela√ß√£o entre os tokens, mostrando suas tags gramaticais e conex√µes sint√°ticas de maneira intuitiva.  Abaixo √© poss√≠vel ver uma parte dessa an√°lise.

<p align="center">
    <img src="./evidencias/curso de nlp/spacy-display.png" alt="Depend√™ncias" width="500">
</p>

- O **NLTK (Natural Language Toolkit)** √© uma das bibliotecas mais utilizadas para **Processamento de Linguagem Natural (NLP)** em Python. Ele fornece muitas ferramentas para an√°lise de texto, incluindo tokeniza√ß√£o, stemming, lematiza√ß√£o, an√°lise sint√°tica e reconhecimento de entidades nomeadas, como vistas no curso de Spacy.

- Como as t√©cnicas de **NLP** s√£o praticamente as mesmas aplicadas com spacy, optei por n√£o inserir evid√™ncias de processos como tokeniza√ß√£o, POS-Tagging e outros j√° mencionados anteriormente. Por√©m, um ponto interessante que n√£o foi abordado no spacy √© a busca pela **frequ√™ncia de uma palavra em uma senten√ßa**, conforme mostrado na imagem abaixo:  

<p align="center">
    <img src="./evidencias/curso de nlp/nltk-frequency.png" alt="Frequ√™ncias" width="500">
</p>

- **Machine Learning e Deep Learning com NLP na Pr√°tica**:

- **Machine Learning com NLP**: Nesta parte, foi utilizado um **dataset de spam** para prever se um e-mail √© **spam ou n√£o**. Para isso, foram utilizados os passos comuns ao fazer previs√µes:

- **Prepara√ß√£o dos dados**: Separa√ß√£o das vari√°veis em features e target.  
- **Vetoriza√ß√£o**: Aplica√ß√£o do `TfidfVectorizer` para converter os textos em representa√ß√µes num√©ricas.  
- **Treinamento do modelo**: Utiliza√ß√£o do algoritmo **Random Forest** para aprendizado.  
- **Avalia√ß√£o**: Foram realizadas previs√µes e as m√©tricas obtidas demonstraram um bom desempenho do modelo. 

Por√©m, ao inserir **novos dados**, o modelo apresentou erro na previs√£o, conforme ilustrado na imagem abaixo. Mas isso n√£o significa que o modelo tem desempenho ruim.

<p align="center">
    <img src="./evidencias/curso de nlp/ml-spam.png" alt="Frequ√™ncias" width="500">
</p>

- **Deep Learning com NLP**: O mesmo problema foi abordado utilizando **Redes Neurais**, seguindo um fluxo semelhante, mas usando uma abordagem diferente de vetoriza√ß√£o com o `CountVectorizer` e **redes neurais** para treinamento.

- **An√°lise de Sentimentos**:
Para a an√°lise de sentimentos, foram testadas diferentes abordagens, incluindo:  
- **LSTM (Long Short-Term Memory)**  
- **BERT (Bidirectional Encoder Representations from Transformers)**  
- **Regras Supervisionadas**  

Contudo, o exemplo apresentado abaixo utiliza o **Vader**, uma ferramenta baseada em regras, otimizada para an√°lise de sentimentos em textos curtos, como coment√°rios e tamb√©m tweets. No exemplo, foram utilizada senten√ßas simples e atrav√©s do `mas.popularity_score()` foi poss√≠vel obter as m√©tricas correspondentes as tr√™s classes negativo, positivo, neutro.

<p align="center">
    <img src="./evidencias/curso de nlp/vader-analise-sentimentos.png" alt="Vader" width="500">
</p>

- Outra parte bem legal dos cursos foi a utiliza√ß√£o do **Transformers** com o **Hugging Face Hub**. Atrav√©s deles, foi poss√≠vel testar modelos j√° treinados para diferentes tarefas de NLP.  

Primeiramente, exploramos a funcionalidade de **Perguntas e Respostas**, onde um modelo recebe um texto e responde perguntas com base nele. Outra aplica√ß√£o interessante foi o **preenchimento de lacunas**, onde o modelo completa palavras faltantes dentro de uma frase, demonstrando sua capacidade contextual.

<p align="center">
    <img src="./evidencias/curso de nlp/pergunta-resposta.png" alt="*" width="400">
    <img src="./evidencias/curso de nlp/lacunas.png" alt="#" width="400">
</p>

### MLOps: Implata√ß√£o e Opera√ß√£o de Modelos de Machine Learning
O curso de MLOps foi de longe um dos mais interessantes e proveitsos da trilha. Nesse curso foi poss√≠vel entender o processo por tr√°s do registro e implanta√ß√£o de um modelo de machine learning utilizando **MLFlow**.

Com o MLflow, foi poss√≠vel:  
- **Registrar modelos treinados** e acompanhar suas vers√µes. Posteriormente foi poss√≠vel**interagir com a interface do MLflow**, visualizando m√©tricas e artefatos dos experimentos.  

- O primeiro modelo a ser registrado foi o de **Naive Bayes**:
<p align="center">
    <img src="./evidencias/curso mlops/mlflow-ui.png" alt="MLFLOW" width="600">
</p>

Outro ponto interessante √© que foi poss√≠vel gerar gr√°ficos para ter uma no√ß√£o do desempenho, como o gr√°fico de **Matriz de Confus√£o** e o gr√°fico de **ROC**:

<p align="center">
    <img src="./evidencias/curso mlops/matriz1.png" alt="Matriz de Confus√£o" width="400">
    <img src="./evidencias/curso mlops/roc1.png" alt="ROC" width="400">
</p>

- O segundo modelo a ser registrado foi o de **Random Forest**:
<p align="center">
    <img src="./evidencias/curso mlops/mlflow-ui2.png" alt="MLFLOW" width="600">
</p>

O modelo possui mais registros pois a execu√ß√£o foi atrav√©s de um looping aumentando o n√∫mero de √°rvores a cada vez que rodasse, sendo primeiro com 50, depois 100, 500, 750 e 1000. Abaixo, segue a compara√ß√£o da matriz de confus√£o com todas as cinco quantidades de √°rvores mencionadas anteriormente.

<p align="center">
    <img src="./evidencias/curso mlops/matriz_rf1.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf2.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf3.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf4.png" alt="Matriz de Confus√£o" width="300">
    <img src="./evidencias/curso mlops/matriz_rf5.png" alt="Matriz de Confus√£o" width="300">
</p>

Melhor modelo:
O √∫ltimo modelo (27,64,12,197) teve:

- Menor n√∫mero de Falsos Negativos (12) ‚Üí Ele errou menos ao n√£o identificar positivos.
- Maior n√∫mero de Verdadeiros Positivos (197) ‚Üí Ele acertou mais previs√µes positivas.


- O terceiro modelo a ser registrado foi utilizando o **Keras**:
<p align="center">
    <img src="./evidencias/curso mlops/mlflow-ui3.png" alt="MLFLOW" width="600">
</p>

### Face Recognition with Machine Learning
O curso de Face Recognition foi bem interessante, abordando temas desde a detec√ß√£o com OpenCV at√© a detec√ß√£o com modelos de Machine Learning.

- **OpenCV**: Sobre a detec√ß√£o com OpenCV, um dos pontos que foi bem legal inicialmente, foi poder conhecer mais sobre como o padr√£o RGB modifica as imagens. Nessa se√ß√£o, foram feitos transforma√ß√µes usando bibliotecas como o OpenCV propriamente, Matplotlib e Pillow. O OpenCV l√™ a imagem com padr√£o BGR, diferentemente do Matplotlib e Pillow que leem com RGB. Na imagem abaixo isso √© refor√ßado.

<p align="center">
    <img src="./evidencias/curso reconhecimento facial/ev2-display.png" alt="FaceRecognition" width="600">
</p>

Posteriormente, foi ensinado como fazer a convers√£o do BGR para RGB e tamb√©m foi ensinado sobre a transforma√ß√£o GrayScale, essa que ajuda bastante ao fazer o reconhecimento facial. Al√©m disso, tamb√©m foi feito o *"crop"* dos rostos e marcado com ret√¢ngulo verde, como uma forma de demonstrar como seria feito posteriormente com machine learning. O mesmo processo foi realizado com v√≠deos e utilizei o novo trailer de Quarteto Fantastico para testar e funcionou muito bem!

<p align="center">
    <img src="./evidencias/curso reconhecimento facial/face-detection.png" alt="FaceRecognition" width="300">
</p>

- **Face Recognition com Machine Learning**: Para fazer a detec√ß√£o com machine learning houve o uso do **Haar Cascade Classifier** para detec√ß√£o e extra√ß√£o de rostos em imagens e v√≠deos, separados por g√™nero feminino e masculino.

<p align="center">
    <img src="./evidencias/curso reconhecimento facial/male-female.png" alt="FaceRecognition" width="600">
</p>

## üèÜ Certificados

Segue abaixo os certificados obtidos nos cursos da Sprint 06:

1. **Processamento de Linguagem Natural**
![Certificado 1](./certificados/Curso%20Forma√ß√£o%20de%20Processamento%20de%20Linguagem%20Natural.jpg)  

2. **Reconhecimento Facial**
![Certificado 2](./certificados/Curso%20Face%20Recognition%20with%20Machine%20Learning.jpg)

3. **MLOps**
![Certificado 3](./certificados/Curso%20MLops.jpg)  


