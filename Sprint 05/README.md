# üìä Entrega - Sprint 05

Nessa sprint 05, o objetivo na trilha era desenvolver um projeto de **previs√£o de pre√ßo de carros usados** com regress√£o, utilizando machine learning e os conhecimentos adquiridos nos cursos anteriores.

## Link do V√≠deo
https://compasso-my.sharepoint.com/:v:/r/personal/emanuelle_lima_pb_compasso_com_br/Documents/sprint05-desafio2-emanuelle.lima.mp4?csf=1&web=1&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=czMWnN

---

# üíª Projeto

‚û°Ô∏è Confira o notebook do [projeto de previs√£o](./previsao-carros.ipynb).

Para realizar o projeto foram necess√°rias as importa√ß√µes de algumas bibliotecas como: 
 - `pandas`, `numpy`, `seaborn`, `matplotlib`, `shap` e `scikit-learn`.

Al√©m disso, para conseguir visualizar e realizar as altera√ß√µes na base de dados, √© necess√°rio ter o arquivo [cars](https://drive.google.com/file/d/1pw1gp1z7jHKi1ynRgFfY4yEvYbHOLLHg/view?usp=drive_link) presente no meu google drive.

## üõ†Ô∏è Etapas do Projeto

- **Amostragem de Dados**: Foi realizada uma amostragem de **25% dos dados** com uma amostra reprodut√≠vel (usando `random_state`). O novo conjunto de dados foi composto por cerca de 190 mil registros.
 <p align="center">
    <img src="./evidencias/amostragem.png" alt="Amostragem" width="400">
  </p>

- **An√°lise Explorat√≥ria dos Dados**: Na etapa de EDA, a an√°lise das vari√°veis num√©ricas foi feita com a estat√≠stica descritiva e gera√ß√£o de gr√°ficos como Boxplot, para analisar a ocorr√™ncia de outliers e Histogramas para visualizar a distribui√ß√£o dos dados nas vari√°veis. Para representar graficamente as an√°lises das vari√°veis categ√≥ricas, foi utilizado gr√°ficos CountPlots.

  - **Boxplots** das var√≠aveis de `price`, `price_drop` e `mileage` (p√≥s tratamento) respectivamente:
  <p align="center">
    <img src="./evidencias/boxprice.png" alt="Boxplot de Price" width="300">
    <img src="./evidencias/boxprice-drop.png" alt="Boxplot de Price Drop" width="300">
    <img src="./evidencias/boxmileage.png" alt="Boxplot de Mileage" width="300">
  </p>

  Foram removidos outliers em `mileage` acima de 350k de milhas percorridas e na vari√°vel `price` removi apenas o registro que estava preenchido incorretamente, uma vez que a maioria dos valores considerados outliers s√£o os pre√ßos reais dos carros. Sobre a vari√°vel `price_drop`, por ter mais de 80k de valores faltantes (mostrarei posteriormente) e por fazer o XAI e verificar que n√£o foi uma vari√°vel considerada importante para o meu modelo, dropei a coluna.

  - **Histogramas** das vari√°veis num√©ricas mais importantes para analisar a distribui√ß√£o:
  <p align="center">
    <img src="./evidencias/histprice.png" alt="Histograma de Price" width="300">
    <img src="./evidencias/histprice-drop.png" alt="Histograma de Price Drop" width="300">
    <img src="./evidencias/histyear.png" alt="Histograma de Year" width="300">
  </p>
  <p align="center">
    <img src="./evidencias/histmileage.png" alt="Histograma de Mileage" width="300">
    <img src="./evidencias/histsellerrat.png" alt="Histograma de Seller Rating" width="300">
    <img src="./evidencias/histdrivernum.png" alt="Histograma de Driver Reviews" width="300">
  </p>
  Pode-se perceber que a maioria das distribui√ß√µes nos histogramas s√£o assim√©tricas.

  - **Vari√°veis Categ√≥ricas e CountPlots**: Para visualizar a propor√ß√£o das categorias foram utilizados alguns gr√°ficos (CountPlots) e agrupamentos:
  <p align="center">
    <img src="./evidencias/model.png" alt="Model" width="300">
    <img src="./evidencias/manufacturer.png" alt="Manufacturer" width="300">
    <img src="./evidencias/engine.png" alt="Engine" width="300">
  </p>
  <p align="center">
    <img src="./evidencias/drivetrain.png" alt="Drive Train" width="300">
    <img src="./evidencias/fueltype.png" alt="Fuel Type" width="300">
    <img src="./evidencias/mpg.png" alt="MPG" width="300">
  </p>

  Analisando as vari√°veis, √© percept√≠vel que a maioria delas tem uma boa disposi√ß√£o, com exce√ß√£o da vari√°vel `fuel_type` na qual o tipo *Gasolina* foi a categoria com maior propor√ß√£o.

  Algumas vari√°veis, ao chamar o m√©todo dtypes do *pandas* possuiam o tipo como float, por√©m s√£o vari√°veis categ√≥ricas de classifica√ß√£o bin√°ria, s√£o elas:

   <p align="center">
    <img src="./evidencias/acidentes.png" alt="Accidents Damage" width="300">
    <img src="./evidencias/unicodono.png" alt="One Owner" width="300">
    <img src="./evidencias/usopessoal.png" alt="Personal Use Only" width="300">
  </p>

  Importante destacar que a coluna de classifica√ß√£o 0.0 √© correspondente a *n√£o* e a coluna 1.0 √© correspondente a *sim*.

  - Para as **vari√°veis num√©ricas** foi feito o gr√°fico de correla√ß√£o de *Pearson* para analisar o quanto as vari√°veis est√£o associadas a vari√°vel objetivo.
  <p align="center">
    <img src="./evidencias/corr1.png" alt="Accidents Damage" width="400">
  </p>

  - **Valores Faltantes e Duplicados**:
   - Foram identificados `588` registros duplicados atrav√©s do m√©todo `duplicated()` do *pandas*, que foram removidos logo em seguida.

   - Para verificar a ocorr√™ncia de valores faltantes, foi chamado o m√©todo `isnull().sum()` do *pandas*, e o resultado foi o seguinte:

   <p align="center">
    <img src="./evidencias/nan.png" alt="Valores Faltantes" width="400">
  </p>
  
   - Para tratar os dados faltantes, primeiro foi feita uma an√°lise com t√©cnica de XAI (Machine Learning Explic√°vel), sendo o **Shap Values** para identificar quais vari√°veis mais causariam impacto no meu modelo. Para isso, treinei alguns modelos com o mesmo dataset usando algoritmos de Regress√£o Linear, Random Forest e √Årvores de Decis√£o, e posteriormente usei o Shap Values para obter as "melhores" vari√°veis. Dado isso, escolhi as oito melhores vari√°veis nesses testes. Assim, tratei os valores nulos apenas dessas vari√°veis e dropei as restantes. Abaixo, segue os resultados do Shap Values:

   <p align="center">
    <img src="./evidencias/shap_rl.png" alt="#" width="300">
    <img src="./evidencias/shap_rf.png" alt="#" width="300">
    <img src="./evidencias/shap_dt.png" alt="#" width="300">
  </p>

  Realizar a etapa da EDA de uma forma mais completa, podendo fazer testes e analisando cada uma das 20 vari√°veis foi muito satisfat√≥rio, uma vez que no primeiro projeto a minha an√°lise acabou sendo mais b√°sica, at√© mesmo por falta de experi√™ncia. Ent√£o foi bastante gratificante conseguir desenvolver essa etapa de EDA de uma forma completa, descobrindo padr√µes e obtendo insights.

- **Pr√©-Processamento dos Dados**: Nessa etapa, realizei o tratamento (limpeza) e a transforma√ß√£o dos dados, al√©m da divis√£o dos dados em treino e teste.
  - **Tratamento e limpeza**: Foram feitas as limpezas dos dados removendo as duplicatas e tratando os valores nulos.
  <p align="center">
    <img src="./evidencias/nan_mpg.png" alt="#" width="400">
    <img src="./evidencias/nan_tratado.png" alt="#" width="300">
  </p>

Para tratar os valores de `mpg` e `drivetrain` achei interessante fazer uma distruibui√ß√£o dos valores recorrentes dessas vari√°veis dado o modelo espec√≠fico do carro que quero preencher o dado faltante. Para tratar os dados de `engine` preferi dropar os valores. As outras vari√°veis que posteriormente ser√£o usadas no treinamento do modelo n√£o possuiam valores nulos (imagem a direita).

  - **Divis√£o do conjunto de dados e Codifica√ß√£o**: Nessa etapa foi realizada a codifica√ß√£o de r√≥tulos com `LabelEncoder` e `TargetEncoder` e a separa√ß√£o das vari√°veis **X (features)** e **y (target)**.
  <p align="center">
    <img src="./evidencias/encoder-separacao.png" alt="#" width="400">
  </p>

A escolha dos algoritmos acima se deu principalmente pela escolha do algoritmo de treinamento do modelo, o **Random Forest** √© conhecido por n√£o criar rela√ß√µes ordinais. Outro ponto, √© que para as vari√°veis com poucas categorias foi aplicado o `LabelEncoder`, j√° para vari√°veis com muitas categorias foi aplicado o `TargetEncoder`.

  - **Matriz de correla√ß√£o**: Posteriormente, achei interessanre fazer a identifica√ß√£o das vari√°veis mais correlacionadas com o pre√ßo do carro usando o gr√°fico de correla√ß√£o de *Pearson* e de *Spearman*.
  <p align="center">
    <img src="./evidencias/corr2.png" alt="#" width="400">
    <img src="./evidencias/corr3.png" alt="#" width="400">
  </p>

  - Por √∫ltimo foi feita a divis√£o em **dados de treino e teste** usando `train_test_split`, sendo 70% do conjunto de dados para treino e 30% para teste.

- **Cria√ß√£o, Treinamento e Previs√µes do Modelo**:
  - **Modelo escolhido:** Regressor baseado em **Random Forest**.
  - **Treinamento:** Utiliza√ß√£o do m√©todo `fit()` para ajustar o modelo aos dados de treino.
  - **Previs√µes:** Realizadas com o m√©todo `predict()` no conjunto de teste.

  <p align="center">
    <img src="./evidencias/fit.png" alt="#" width="400">
    <img src="./evidencias/predict.png" alt="#" width="400">
  </p>

- **Avalia√ß√£o e M√©tricas**: Nessa etapa, foi realizada a avalia√ß√£o da performance do modelo utilizando o `score()` e as duas principais m√©tricas sendo `mean_absolute_error` e `mean_squared_error`. Os resultados obtidos foram:
  <p align="center">
    <img src="./evidencias/metrics.png" alt="#" width="400">
  </p>
  
  Com base nas m√©tricas acima, a conclus√£o foi de que o modelo √© um bom modelo, conseguindo prever e desempenhar bem. A m√©dia de erro foi baixa ao pensar no contexto dos pre√ßos dos carros e de como s√£o altos. O score de 89% tamb√©m indica um bom resultado, mostrando que o modelo consegue capturar bem a rela√ß√£o entre as features e a vari√°vel objetivo. Dessa forma, tamb√©m foi notado que apesar de serem boas m√©tricas, ainda cabem melhoras e fica como exerc√≠cio de limita√ß√£o para serem superados realizado, por exemplo, mudan√ßas nos par√¢metros ou utilizando outros algoritmos de codifica√ß√£o.

- **Vari√°veis com maior import√¢ncia**: Por √∫ltimo, era necess√°rio encontrar as vari√°veis que mais impactaram no modelo, para isso utilizei uma *T√©cnica de Explainable AI (XAI)*, sendo o uso dos valores de **SHAP** para identificar as duas vari√°veis mais importantes para o modelo. O resultado entregue pelo *Shap Values* foi de que as vari√°veis `model` e `mileage` s√£o as mais importantes. Veja abaixo:

  <p align="center">
    <img src="./evidencias/shap_final.png" alt="#" width="400">
  </p>

- **Compara√ß√£o com Outros Algoritmos**: Para verificar qual algoritmo de regress√£o obteria o melhor desempenho, treinei o dataset com modelos como `Regress√£o Linear`, `√Årvores de Decis√£o`, `Redes Neuraus` e `Random Forest` e ap√≥s o treinamento avaliei cada modelo. Os resultados:

| Modelo               | MAE (Erro M√©dio Absoluto) | MSE (Erro Quadr√°tico M√©dio) | Score (R¬≤) |
|----------------------|---------------------------|-----------------------------|------------|
| **Random Forest**    | 2.811,35                 | 51.137.539,68              | 0,89       |
| **√Årvores de Decis√£o** | 3.560,51                 | 67.936.018,31              | 0,85       |
| **Redes Neurais**    | 4.145,16                 | 60.055.569,08              | 0,86       |
| **Regress√£o Linear** | 8.542,00                 | 236.087.880,64             | 0,46       |

Como pode ser observado na tabela acima, o algoritmo de **Random Forest** obteve o melhor desempenho nas m√©tricas, e devido a isso e a sua robustez ele foi o algoritmo escolhido para desempenhar no projeto.

Destarte, atrav√©s desse projeto foi cumprido o desafio de fazer as previs√µes de pre√ßos de carros usados, usando um algoritmo de regress√£o que foi o Random Forest. O modelo com esse algoritmo teve um bom desempenho, sobretudo comparado aos outros citados acima, com score de 89%. Esse projeto foi uma oportunidade enriquecedora e muito satisfat√≥ria de colocar em pr√°tica os conhecimentos adquiridos nos cursos do programa.

## Refer√™ncias

- GeeksforGeeks. Steps for Mastering Exploratory Data Analysis (EDA). Dispon√≠vel em: https://www.geeksforgeeks.org/steps-for-mastering-exploratory-data-analysis-eda-steps/

- Scikit-learn. Scikit-learn: Machine Learning in Python. Dispon√≠vel em: https://scikit-learn.org/stable/

- DataCamp. Introduction to SHAP Values: Machine Learning Interpretability. Dispon√≠vel em: https://www.datacamp.com/tutorial/introduction-to-shap-values-machine-learning-interpretability


  
  